{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from queries import start_elastic_search, index_documents\n",
    "from trec_files import make_trec_run2\n",
    "from trec_files import read_eval_files\n",
    "from evaluation import trec_eval\n",
    "from evaluation import mean_average_precision\n",
    "import elasticsearch\n",
    "import elasticsearch.helpers\n",
    "import json\n",
    "from elasticsearch import Elasticsearch\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from elasticsearch_dsl import Q\n",
    "from elasticsearch_dsl import Search\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ut-student/.local/lib/python3.8/site-packages/elasticsearch/connection/base.py:200: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(263080, [])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to the ElasticSearch server\n",
    "es = elasticsearch.Elasticsearch(host='localhost')  # in case you use Docker, the host is 'elasticsearch'\n",
    "\n",
    "# Index the collection into the index called 'genomics'\n",
    "body = {} # no indexing options (leave default)\n",
    "index_documents(es, 'data01/FIR-s05-medline.json', 'genomics-base', body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# connect to ES server             \n",
    "es = elasticsearch.Elasticsearch('localhost')\n",
    "# Write the results of the queries contained in the topic file `'data/training-queries-simple.txt'` \n",
    "# to the run file `'baseline.run'`, and name this test as `test01`\n",
    "make_trec_run(es, 'data01/FIR-s05-training-queries-simple.txt', 'baseline.run', \"genomics-base\", run_name='test01')\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for baseline.run\n",
      "mean success_at_1              0.1053\n",
      "mean success_at_5              0.2632\n",
      "mean success_at_10             0.3158\n",
      "mean r_precision               0.09156\n",
      "mean precision_at_1            0.1053\n",
      "mean precision_at_5            0.07895\n",
      "mean precision_at_10           0.04737\n",
      "mean precision_at_50           0.01947\n",
      "mean precision_at_100          0.01395\n",
      "mean precision_at_recall_00    0.2015\n",
      "mean precision_at_recall_01    0.1898\n",
      "mean precision_at_recall_02    0.1683\n",
      "mean precision_at_recall_03    0.1333\n",
      "mean precision_at_recall_04    0.1236\n",
      "mean precision_at_recall_05    0.1227\n",
      "mean precision_at_recall_06    0.08744\n",
      "mean precision_at_recall_07    0.08435\n",
      "mean precision_at_recall_08    0.05999\n",
      "mean precision_at_recall_09    0.05803\n",
      "mean precision_at_recall_10    0.05803\n",
      "mean average_precision         0.1116\n"
     ]
    }
   ],
   "source": [
    "print_trec_eval('data01/FIR-s05-training-qrels.txt', 'baseline.run')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pseudo-Feedback Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize NLTK components\n",
    "stop_words = set(stopwords.words('english'))\n",
    "porter = PorterStemmer()\n",
    "\n",
    "# Function for text preprocessing\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [porter.stem(token) for token in tokens if token.isalpha() and token not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Perform an initial query\n",
    "initial_query = {\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"field_to_search\": preprocess_text(\"your initial query\")\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "initial_results = es.search(index='your_index_name', body=initial_query, size=10)\n",
    "\n",
    "# Extract the initial retrieved documents' content\n",
    "docs_content = [hit['_source']['field_to_extract'] for hit in initial_results['hits']['hits']]\n",
    "\n",
    "# Combine the initial query with terms from the top retrieved documents\n",
    "feedback_terms = []\n",
    "for doc_content in docs_content:\n",
    "    doc_tokens = word_tokenize(doc_content)\n",
    "    doc_tokens = [porter.stem(token) for token in doc_tokens if token.isalpha() and token not in stop_words]\n",
    "    feedback_terms.extend(doc_tokens)\n",
    "\n",
    "# Calculate term frequencies for the feedback terms\n",
    "feedback_term_freq = {}\n",
    "for term in feedback_terms:\n",
    "    if term in feedback_term_freq:\n",
    "        feedback_term_freq[term] += 1\n",
    "    else:\n",
    "        feedback_term_freq[term] = 1\n",
    "\n",
    "# Sort the feedback terms by their frequency\n",
    "sorted_feedback_terms = sorted(feedback_term_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Choose the top feedback terms to expand the query\n",
    "num_feedback_terms = 5\n",
    "expanded_query = {\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"field_to_search\": {\n",
    "                \"query\": preprocess_text(\"your initial query\"),\n",
    "                \"operator\": \"or\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "for term, _ in sorted_feedback_terms[:num_feedback_terms]:\n",
    "    expanded_query[\"query\"][\"match\"][\"field_to_search\"][\"query\"] += f\" {term}\"\n",
    "\n",
    "# Perform a new search with the expanded query\n",
    "new_results = es.search(index='your_index_name', body=expanded_query, size=10)\n",
    "\n",
    "# You can now work with the new search results in 'new_results'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels_file = \"data01/trec.qrels\"\n",
    "run_file = \"data01/baseline.run\"\n",
    "\n",
    "# Read the relevant documents and retrieved documents\n",
    "all_relevant, all_retrieved = read_eval_files(qrels_file, run_file)\n",
    "\n",
    "# Evaluate the performance\n",
    "map_score = mean_average_precision(all_relevant, all_retrieved)\n",
    "print(f\"Mean Average Precision (MAP): {map_score}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
